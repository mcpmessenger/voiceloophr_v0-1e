import { type NextRequest, NextResponse } from "next/server"

export async function POST(request: NextRequest) {
  try {
    const { message, fileId, openaiKey } = await request.json()

    // Require both message and OpenAI key; prefer hard fail over simulation
    if (!message || !openaiKey) {
      return NextResponse.json({ error: "Missing message or OpenAI key" }, { status: 400 })
    }

    // Get file context if fileId provided
    let context = ""
    if (fileId) {
      global.uploadedFiles = global.uploadedFiles || new Map()
      const fileData = global.uploadedFiles.get(fileId)
      if (fileData && fileData.extractedText) {
        context = fileData.extractedText
      }
    }

    // Simulate AI chat response
    await new Promise((resolve) => setTimeout(resolve, 1000))

    const simulatedResponse = `Based on ${fileId ? "your document" : "the conversation"}, I can help answer your question: "${message}". 

${fileId ? "From the document context, " : ""}Here's what I found relevant to your query. In a real implementation, this would be a contextual response generated by GPT-4 that analyzes your specific document content and provides accurate, helpful answers.

Would you like me to elaborate on any particular aspect or help you with something else?`

    return NextResponse.json({
      success: true,
      response: simulatedResponse,
      hasContext: !!fileId,
    })

    /* Real implementation would be:
    const messages = [
      {
        role: 'system',
        content: `You are a helpful AI assistant that answers questions about documents. ${
          context ? `Here is the document context: ${context}` : ''
        }`
      },
      {
        role: 'user',
        content: message
      }
    ]

    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${openaiKey}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        model: 'gpt-4',
        messages,
        max_tokens: 500,
        temperature: 0.7
      })
    })

    const result = await response.json()
    return NextResponse.json({ 
      success: true, 
      response: result.choices[0].message.content,
      hasContext: !!context
    })
    */
  } catch (error) {
    console.error("Chat error:", error)
    return NextResponse.json({ error: "Chat failed" }, { status: 500 })
  }
}
